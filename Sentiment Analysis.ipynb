{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb55af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
      "Dataset URL: https://www.kaggle.com/datasets/tleonel/cost-of-living\n",
      "License(s): CC0-1.0\n",
      "costofliving-query-tweets.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download tleonel/cost-of-living -f costofliving-query-tweets.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3387a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ba4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref= zipfile.ZipFile('costofliving-query-tweets.csv.zip')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8037ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_like_count</th>\n",
       "      <th>tweet_retweet_count</th>\n",
       "      <th>tweet_reply_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-09 00:19:49+00:00</td>\n",
       "      <td>Beer_Enjoyer420</td>\n",
       "      <td>District of Columbia, USA</td>\n",
       "      <td>I like news, weather, and sports updates! (And...</td>\n",
       "      <td>False</td>\n",
       "      <td>87</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>\"UPS affects virtually every American and here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-09 00:19:48+00:00</td>\n",
       "      <td>MLAIrfanSabir</td>\n",
       "      <td>Calgary, Treaty 7 Territory</td>\n",
       "      <td>The official account of MLA Irfan Sabir, JSS C...</td>\n",
       "      <td>True</td>\n",
       "      <td>7432</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>The UCP is not capable of giving Albertans a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-09 00:19:04+00:00</td>\n",
       "      <td>AFDJnews</td>\n",
       "      <td>Australia</td>\n",
       "      <td>ADFJ is your top Australian farming industry n...</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://help.twitter.com/en/using-twi...</td>\n",
       "      <td>Cost of living pushed up by climate-driven flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-09 00:18:51+00:00</td>\n",
       "      <td>LitmusTree</td>\n",
       "      <td>Yah Dads House</td>\n",
       "      <td>ðŸ‡¹ðŸ‡¼You looked through my profile after you saw ...</td>\n",
       "      <td>False</td>\n",
       "      <td>56</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>@IIPatricio_ @Askechadd @emexdizzy @twinkbride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-09 00:18:23+00:00</td>\n",
       "      <td>athenastits</td>\n",
       "      <td>they/them | 18 | uk | leftist</td>\n",
       "      <td>if it's not our flag means death it's the old ...</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>there's a massive cost of living crisis in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144957</th>\n",
       "      <td>2022-08-20 20:19:10+00:00</td>\n",
       "      <td>MaryTracy</td>\n",
       "      <td>England</td>\n",
       "      <td>Writer. Web Designer. Yoga teacher. #Yoga #Spi...</td>\n",
       "      <td>False</td>\n",
       "      <td>2277</td>\n",
       "      <td>2298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Eye opening thread on the cost of living in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144958</th>\n",
       "      <td>2022-08-20 20:18:57+00:00</td>\n",
       "      <td>_Fessial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ModusPonens</td>\n",
       "      <td>False</td>\n",
       "      <td>767</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>@KamalaHarris thats because people doing 2-3 j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144959</th>\n",
       "      <td>2022-08-20 20:18:47+00:00</td>\n",
       "      <td>billyphillyboi</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Phillies|Eagles|Sixers|Packers|Sports and Poli...</td>\n",
       "      <td>False</td>\n",
       "      <td>2763</td>\n",
       "      <td>2860</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>@CheerSquad88 @JoshShapiroPA Nothing, he's goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144960</th>\n",
       "      <td>2022-08-20 20:18:23+00:00</td>\n",
       "      <td>AnnaDe_2015</td>\n",
       "      <td>London</td>\n",
       "      <td>Global/European healthcare public affairs prof...</td>\n",
       "      <td>False</td>\n",
       "      <td>934</td>\n",
       "      <td>1855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Looks like the UK governmentâ€™s feeble attempts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144961</th>\n",
       "      <td>2022-08-20 20:17:49+00:00</td>\n",
       "      <td>NzuchiTimesUSA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Nzuchi Times is a fast-growing news site with ...</td>\n",
       "      <td>False</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
       "      <td>Cost of living: Help is coming, says KwasiÂ Kwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144962 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date_time         username  \\\n",
       "0       2022-09-09 00:19:49+00:00  Beer_Enjoyer420   \n",
       "1       2022-09-09 00:19:48+00:00    MLAIrfanSabir   \n",
       "2       2022-09-09 00:19:04+00:00         AFDJnews   \n",
       "3       2022-09-09 00:18:51+00:00       LitmusTree   \n",
       "4       2022-09-09 00:18:23+00:00      athenastits   \n",
       "...                           ...              ...   \n",
       "144957  2022-08-20 20:19:10+00:00        MaryTracy   \n",
       "144958  2022-08-20 20:18:57+00:00         _Fessial   \n",
       "144959  2022-08-20 20:18:47+00:00   billyphillyboi   \n",
       "144960  2022-08-20 20:18:23+00:00      AnnaDe_2015   \n",
       "144961  2022-08-20 20:17:49+00:00   NzuchiTimesUSA   \n",
       "\n",
       "                        user_location  \\\n",
       "0           District of Columbia, USA   \n",
       "1         Calgary, Treaty 7 Territory   \n",
       "2                           Australia   \n",
       "3                      Yah Dads House   \n",
       "4       they/them | 18 | uk | leftist   \n",
       "...                               ...   \n",
       "144957                        England   \n",
       "144958                            NaN   \n",
       "144959               Philadelphia, PA   \n",
       "144960                        London    \n",
       "144961                            USA   \n",
       "\n",
       "                                         user_description  verified  \\\n",
       "0       I like news, weather, and sports updates! (And...     False   \n",
       "1       The official account of MLA Irfan Sabir, JSS C...      True   \n",
       "2       ADFJ is your top Australian farming industry n...     False   \n",
       "3       ðŸ‡¹ðŸ‡¼You looked through my profile after you saw ...     False   \n",
       "4       if it's not our flag means death it's the old ...     False   \n",
       "...                                                   ...       ...   \n",
       "144957  Writer. Web Designer. Yoga teacher. #Yoga #Spi...     False   \n",
       "144958                                       #ModusPonens     False   \n",
       "144959  Phillies|Eagles|Sixers|Packers|Sports and Poli...     False   \n",
       "144960  Global/European healthcare public affairs prof...     False   \n",
       "144961  Nzuchi Times is a fast-growing news site with ...     False   \n",
       "\n",
       "        followers_count  following_count  tweet_like_count  \\\n",
       "0                    87              270                 0   \n",
       "1                  7432              854                 0   \n",
       "2                    26               77                 0   \n",
       "3                    56              251                 0   \n",
       "4                    52              154                 0   \n",
       "...                 ...              ...               ...   \n",
       "144957             2277             2298                 1   \n",
       "144958              767              571                 0   \n",
       "144959             2763             2860                 3   \n",
       "144960              934             1855                 0   \n",
       "144961              575                4                 0   \n",
       "\n",
       "        tweet_retweet_count  tweet_reply_count  \\\n",
       "0                         0                  0   \n",
       "1                         0                  0   \n",
       "2                         0                  0   \n",
       "3                         0                  0   \n",
       "4                         0                  0   \n",
       "...                     ...                ...   \n",
       "144957                    0                  0   \n",
       "144958                    0                  0   \n",
       "144959                    0                  1   \n",
       "144960                    0                  0   \n",
       "144961                    0                  0   \n",
       "\n",
       "                                                   source  \\\n",
       "0       <a href=\"http://twitter.com/download/android\" ...   \n",
       "1       <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2       <a href=\"https://help.twitter.com/en/using-twi...   \n",
       "3       <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4       <a href=\"http://twitter.com/download/android\" ...   \n",
       "...                                                   ...   \n",
       "144957  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "144958  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "144959  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "144960  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "144961  <a href=\"http://publicize.wp.com/\" rel=\"nofoll...   \n",
       "\n",
       "                                               tweet_text  \n",
       "0       \"UPS affects virtually every American and here...  \n",
       "1       The UCP is not capable of giving Albertans a c...  \n",
       "2       Cost of living pushed up by climate-driven flo...  \n",
       "3       @IIPatricio_ @Askechadd @emexdizzy @twinkbride...  \n",
       "4       there's a massive cost of living crisis in the...  \n",
       "...                                                   ...  \n",
       "144957  Eye opening thread on the cost of living in th...  \n",
       "144958  @KamalaHarris thats because people doing 2-3 j...  \n",
       "144959  @CheerSquad88 @JoshShapiroPA Nothing, he's goi...  \n",
       "144960  Looks like the UK governmentâ€™s feeble attempts...  \n",
       "144961  Cost of living: Help is coming, says KwasiÂ Kwa...  \n",
       "\n",
       "[144962 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"costofliving-query-tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723fc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/preethijayakumar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/preethijayakumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/preethijayakumar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"UPS affects virtually every American and here...</td>\n",
       "      <td>ups affect virtually every american here dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The UCP is not capable of giving Albertans a c...</td>\n",
       "      <td>ucp capable giving albertans competent respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cost of living pushed up by climate-driven flo...</td>\n",
       "      <td>cost living pushed climatedriven flood say far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@IIPatricio_ @Askechadd @emexdizzy @twinkbride...</td>\n",
       "      <td>could higher cost cost living wealthy get want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's a massive cost of living crisis in the...</td>\n",
       "      <td>there massive cost living crisis uk rn abt fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  \"UPS affects virtually every American and here...   \n",
       "1  The UCP is not capable of giving Albertans a c...   \n",
       "2  Cost of living pushed up by climate-driven flo...   \n",
       "3  @IIPatricio_ @Askechadd @emexdizzy @twinkbride...   \n",
       "4  there's a massive cost of living crisis in the...   \n",
       "\n",
       "                                  cleaned_tweet_text  \n",
       "0  ups affect virtually every american here dont ...  \n",
       "1  ucp capable giving albertans competent respons...  \n",
       "2  cost living pushed climatedriven flood say far...  \n",
       "3  could higher cost cost living wealthy get want...  \n",
       "4  there massive cost living crisis uk rn abt fun...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stop words, lemmatizer, and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# Define a function to clean and preprocess the text\n",
    "def preprocess_tweet_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs, mentions (@username), and hashtags\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+|@\\S+|#\\S+\", '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and non-alphabetic tokens, and lemmatize the words\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Return the cleaned and preprocessed text as a single string\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Apply the preprocessing to the 'tweet_text' column\n",
    "df['cleaned_tweet_text'] = df['tweet_text'].apply(preprocess_tweet_text)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "df[['tweet_text', 'cleaned_tweet_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d47f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49053a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic 1       Topic 2    Topic 3  Topic 4\n",
      "0     cost        crisis       cost     cost\n",
      "1   living          cost     living   living\n",
      "2   people        living       high   crisis\n",
      "3   crisis  costofliving       wage   energy\n",
      "4     help            uk        pay      amp\n",
      "5    money        energy  inflation    right\n",
      "6     need         truss   increase     like\n",
      "7    going          tory        tax       uk\n",
      "8  support    government      price      war\n",
      "9  payment           new       year  country\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Topic 1': ['cost',\n",
       "  'living',\n",
       "  'people',\n",
       "  'crisis',\n",
       "  'help',\n",
       "  'money',\n",
       "  'need',\n",
       "  'going',\n",
       "  'support',\n",
       "  'payment'],\n",
       " 'Topic 2': ['crisis',\n",
       "  'cost',\n",
       "  'living',\n",
       "  'costofliving',\n",
       "  'uk',\n",
       "  'energy',\n",
       "  'truss',\n",
       "  'tory',\n",
       "  'government',\n",
       "  'new'],\n",
       " 'Topic 3': ['cost',\n",
       "  'living',\n",
       "  'high',\n",
       "  'wage',\n",
       "  'pay',\n",
       "  'inflation',\n",
       "  'increase',\n",
       "  'tax',\n",
       "  'price',\n",
       "  'year'],\n",
       " 'Topic 4': ['cost',\n",
       "  'living',\n",
       "  'crisis',\n",
       "  'energy',\n",
       "  'amp',\n",
       "  'right',\n",
       "  'like',\n",
       "  'uk',\n",
       "  'war',\n",
       "  'country']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Vectorization\n",
    "# Using Count Vectorizer to create a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tweet_term_matrix = vectorizer.fit_transform(df['cleaned_tweet_text'])\n",
    "\n",
    "# Step 2: LDA Model\n",
    "# Define the number of topics\n",
    "num_topics = 4\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_model.fit(tweet_term_matrix)\n",
    "\n",
    "# Step 3: Extracting the topics and their top words\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topics[f\"Topic {topic_idx + 1}\"] = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return topics\n",
    "\n",
    "# Get the feature names (words) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Define the number of top words to display per topic\n",
    "no_top_words = 10\n",
    "\n",
    "# Display the top words for each topic\n",
    "topics = display_topics(lda_model, feature_names, no_top_words)\n",
    "\n",
    "# Convert topics to a DataFrame for better readability and display\n",
    "topics_df = pd.DataFrame(topics)\n",
    "\n",
    "# Display the topics DataFrame\n",
    "print(topics_df)\n",
    "\n",
    "# Return the topics for further use\n",
    "topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e26f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697e2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8133bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 1: General Financial Struggles and Support\n",
    "#Topic 2: Government Response and Political Leadership\n",
    "#Topic 3: Income, Wages, and Inflation\n",
    "#Topic 4: Global Impact on Energy and Economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca9af48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>Assigned Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ups affect virtually every american here dont ...</td>\n",
       "      <td>Income, Wages, and Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ucp capable giving albertans competent respons...</td>\n",
       "      <td>Income, Wages, and Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost living pushed climatedriven flood say far...</td>\n",
       "      <td>Global Impact on Energy and Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could higher cost cost living wealthy get want...</td>\n",
       "      <td>Cost of Living - General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there massive cost living crisis uk rn abt fun...</td>\n",
       "      <td>Cost of Living - General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cleaned_tweet_text  \\\n",
       "0  ups affect virtually every american here dont ...   \n",
       "1  ucp capable giving albertans competent respons...   \n",
       "2  cost living pushed climatedriven flood say far...   \n",
       "3  could higher cost cost living wealthy get want...   \n",
       "4  there massive cost living crisis uk rn abt fun...   \n",
       "\n",
       "                        Assigned Topic  \n",
       "0         Income, Wages, and Inflation  \n",
       "1         Income, Wages, and Inflation  \n",
       "2  Global Impact on Energy and Economy  \n",
       "3             Cost of Living - General  \n",
       "4             Cost of Living - General  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Step 1: Topic Interpretation based on the top words\n",
    "topic_labels = {\n",
    "    0: \"Cost of Living - General\",\n",
    "    1: \"Government Response and Political Leadership\",\n",
    "    2: \"Income, Wages, and Inflation\",\n",
    "    3: \"Global Impact on Energy and Economy\",\n",
    "    \n",
    "}\n",
    "\n",
    "# Step 2: Assigning topics to each tweet\n",
    "# Transform the document-term matrix to get the topic distribution for each tweet\n",
    "tweet_topic_distribution = lda_model.transform(tweet_term_matrix)\n",
    "\n",
    "# Get the most probable topic for each tweet\n",
    "assigned_topics = tweet_topic_distribution.argmax(axis=1)\n",
    "\n",
    "# Map the topic numbers to the interpreted labels\n",
    "assigned_topic_labels = [topic_labels[topic] for topic in assigned_topics]\n",
    "\n",
    "# Add the assigned topic labels to the sampled dataframe\n",
    "df['Assigned Topic'] = assigned_topic_labels\n",
    "\n",
    "# Display the dataframe with the original tweet and the assigned topic\n",
    "df[['cleaned_tweet_text', 'Assigned Topic']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c077cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/preethijayakumar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment                                     Negative   Neutral  Positive\n",
      "Assigned Topic                                                            \n",
      "Cost of Living - General                      0.495482  0.102979  0.401539\n",
      "Global Impact on Energy and Economy           0.733461  0.081591  0.184948\n",
      "Government Response and Political Leadership  0.696926  0.070472  0.232602\n",
      "Income, Wages, and Inflation                  0.409921  0.145559  0.444519\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#I will apply the sentiment analysis on the cleaned tweets from the dataframe\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to categorize sentiment based on the compound score\n",
    "def categorize_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis on the cleaned tweets and categorize them\n",
    "df['Sentiment'] = df['cleaned_tweet_text'].apply(lambda x: sid.polarity_scores(x)['compound']).apply(categorize_sentiment)\n",
    "\n",
    "# Group by the assigned topic and calculate the sentiment distribution\n",
    "sentiment_by_topic = df.groupby('Assigned Topic')['Sentiment'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Display the sentiment by topic\n",
    "print(sentiment_by_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718e08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
